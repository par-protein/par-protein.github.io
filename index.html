<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="description" content="Protein Autoregressive Modeling via Multiscale Structure Generation">
    <meta property="og:title" content="Protein Autoregressive Modeling via Multiscale Structure Generation">
    <meta property="og:description" content="Protein Autoregressive Modeling via Multiscale Structure Generation">
    <!-- <meta property="og:image" content="https://tao-amodal.github.io/static/images/webpage_preview.png"> -->
    <meta property="twitter:title" content="Protein Autoregressive Modeling via Multiscale Structure Generation">
    <meta property="twitter:description" content="Protein Autoregressive Modeling via Multiscale Structure Generation">
    <!-- <meta property="twitter:image" content="https://tao-amodal.github.io/static/images/webpage_preview.png"> -->
    <meta property="og:type" content="website">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="keywords"
        content="PAR, ICML, Protein Autoregressive Modeling, Next-Scale Prediction, Protein Backbone Generation, Flow Matching, Protein">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>Protein Autoregressive Modeling via Multiscale Structure Generation</title>
    <!-- <link rel="icon" type="image/x-icon" href="./static/images/car_icon.png"> -->

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-D65ZW4CJYF"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-D65ZW4CJYF');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="./static/css/animation_style.css"> <!-- Animation styles -->
    <link rel="stylesheet" href="./static/css/style.css"> <!-- Animation styles -->
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">

    <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> -->
    <script src="./static/js/jquery-3.6.4.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/lazy.js"></script>
    <script src="./static/js/faster.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/animation_script.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

</head>

<body>

    <section class="hero" style="border-bottom: 1px solid #dbdbdb;">
        <div class="hero-body" style="padding-bottom: 1.2rem;">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            Protein Autoregressive Modeling <br>via Multiscale Structure Generation
                        </h1>
                        <div class="is-size-6 publication-authors">
                            <span class="author-block">
                                <strong><a href="https://yanruqu.com/">Yanru Qu</a></strong><sup>1,2 *</sup>, 
                            </span>
                            <span class="author-block">
                                <strong><a href="https://wesleyhsieh0806.github.io/">Wesley Hsieh</a></strong><sup>1 *,‚Ä†</sup>, 
                            </span>
                            <span class="author-block">
                                <a href="https://zhengzx-nlp.github.io/">Zaixiang Zheng</a><sup>1</sup>, 
                            </span>
                            <span class="author-block">
                                <a href="https://www.mit.edu/~geliu/">Ge Liu</a><sup>2</sup>, 
                            </span>
                            <span class="author-block">
                                <a href="https://web.cs.ucla.edu/~qgu/">Quanquan Gu</a><sup>1 ‚Ä°</sup>, 
                            </span>
                            <br>
                        </div>
                        
                        <!-- <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://wesleyhsieh0806.github.io/">Wesley Hsieh</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=5JsycngAAAAJ">Xinyou Wang</a><sup>1,2</sup>, </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=hluDH7EAAAAJ">Daiheng Zhang</a><sup>1,3</sup>, </span>
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Dongyu_Xue1">Dongyu Xue</a><sup>1</sup>, </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=4MB4orsAAAAJ">Fei Ye</a><sup>1</sup>, </span>
              <span class="author-block">
                <a href="http://nlp.nju.edu.cn/huangsj/">Shujian Huang</a><sup>2</sup>, </span>
              <span class="author-block">
                <a href="https://zhengzx-nlp.github.io/">Zaixiang Zheng</a><sup>1</sup>, </span>
              <span class="author-block">
                <a href="https://web.cs.ucla.edu/~qgu/">Quanquan Gu</a><sup>1</sup>, </span><br>
            </div> -->

                        <!-- <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Carnegie Mellon University &nbsp; </span>
              <span class="author-block"><sup>2</sup>Toyota Research Institute &nbsp; </span>
              <span class="author-block"><small style="font-size: 0.8em;"><br><sup>*</sup>Equal Contribution</small></span>
              <span class="author-block"><small style="font-size: 0.8em;"><br><sup>‚Ä†</sup>Project Lead</small></span>
              <span class="author-block"><small style="font-size: 0.8em;"><br><sup>‚Ä°</sup>Core Contributor</small></span>
            </div> -->
                        <div class="is-size-6 publication-authors">
                            <span class="author-block"><sup>1</sup>ByteDance Seed</span>
                            &nbsp;&nbsp;
                            <span class="author-block"><sup>2</sup>University of Illinois at Urbana-Champaign </span>
                            &nbsp;&nbsp;
                            <span class="eql-cntrb"><small style="font-size: 0.75em;"><br>
                                <sup>*</sup>Equal Contribution
                                &nbsp;
                                <sup>‚Ä†</sup>Project Lead
                                &nbsp;
                                <sup>‚Ä°</sup>Corresponding Author
                                </small>
                            </span>
                        </div>
                        <!-- <h1 style="font-size:24px">ICCV 2023 (<b>Oral, Best Student Paper</b>)</h1> -->
                        <!-- <h2 class="subtitle is-3 has-text-weight-semibold mt-1 mb-1" style="color: #F05365;"> ICLR 2026
                            (<b>Submission</b>) </h2> -->
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper </span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=KHoAG3gA024"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (Incoming)</span>
                                    </a>
                                </span>
                                <!-- Model Link. -->
                                <!-- <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">ü§ó</span>
                                        <span>Model Checkpoints (Incoming)</span>
                                    </a>
                                </span> -->
                                <!-- Citation Link. -->
                                <span class="link-block">
                                    <a href="#citation" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            üìö
                                        </span>
                                        <span>Citation</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                        <span class="publication-venue" style="font-weight: 500; font-size: 1.9ch; ; margin-top: 0.5rem; margin-bottom: 0.3rem; display: inline-block;">
                            <strong>Protein Autoregressive Modeling:</strong> Taking initiative from the hierarchical nature of proteins, <strong>PAR</strong> generates backbones by forming a global topology and performing refinements, analogous to sculpting a statue into a masterpiece.
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- <style>
    .video-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      /* Three columns */
      grid-template-rows: repeat(1, 1fr);
      /* Two rows */
      gap: 0px 4px;
      /* Gap between videos */
      width: 80%;
      /* Set the container width to 80% */
      margin: 0 auto;
      /* Center the container horizontally */
    }

    .video-grid video {
      width: 100%;
      /* Videos fill the container width */
      height: auto;
    }
  </style> -->

    <br>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-full">
                    <figure class="teaser-figure" style="margin-top: -1rem; margin-bottom: 1rem;">
                        <img src="./static/img/PAR_performance_teaser.png"
                            alt="Performance Teaser" style="width: calc(80% - 0.5rem);">
                        <img src="./static/img/generation_over_scale_with_rmsd_4_samples.png"
                            alt="Multi-scale Generation" style="width: calc(80% - 0.5rem);">
                    </figure>
                </div>
            </div>
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            We present <em>Protein Autoregressive Modeling (PAR)</em>, the <strong>first multi-scale autoregressive framework</strong>
                            for protein backbone generation via coarse-to-fine next-scale prediction. Leveraging the hierarchical nature of proteins,
                            PAR generates structures in a sculpting-like process, forming a coarse topology and progressively refining structural
                            details across scales. PAR consists of three key components: <em>multi-scale downsampling</em> operations that represent
                            protein structures across multiple scales during training; an <em>autoregressive transformer</em> that encodes multi-scale
                            information and produces conditional embeddings to guide structure generation; and a <em>flow-based backbone decoder</em>
                            that generates backbone atoms conditioned on these embeddings. Autoregressive models suffer from <em>exposure bias</em>,
                            caused by the mismatch between training and generation procedures, which can substantially degrade structure generation
                            quality. PAR effectively alleviates this issue through <em>noisy context learning</em> and <em>scheduled sampling</em>,
                            enabling robust backbone generation. Notably, PAR exhibits strong <strong>zero-shot generalization</strong>, supporting
                            flexible human-prompted conditional generation and motif scaffolding <em>without requiring fine-tuning</em>. On
                            unconditional generation benchmarks, PAR effectively learns protein distributions, produces backbones of high design
                            quality, and exhibits favorable scaling behavior, establishing PAR as a promising framework for protein structure
                            generation.
                          </p>
                          
                    </div>
                </div>
            </div>
            <br>
            <!-- Paper video. -->
            <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <a id="overview_video"></a>
            <iframe src="https://www.youtube.com/embed/KHoAG3gA024">
            </iframe>
          </div>
        </div> -->
        </div>
        </div>
        <!--/ Paper video. -->
    </section>

    <style>
        img {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
    </style>

    <style>
        .teaser-figure {
            display: flex;
            flex-wrap: nowrap;
            justify-content: center;
            align-items: center;
            gap: 1rem; /* horizontal spacing between images */
            background-color: #fff;
            /* overflow-x: auto; */
        }
        .teaser-figure img {
            margin: 0;
            height: auto;
        }

        @media (max-width: 768px) {
            .teaser-figure {
                flex-direction: column;
            }
            .teaser-figure img {
                width: 100% !important;
            }
        }
    </style>

    <section>
        <div class="container is-max-desktop content">
            <div class="column is-full-width">
                <div class="toc content mb-5"> <!-- mb-5 adds margin below the TOC -->
                    <h2 class="title is-3" id="Overview">Table of Contents</h2>
                    <ul>
                        <li><a href="#motivation">Motivation</a></li>
                        <li><a href="#contributions">Major Contributions</a></li>
                        <li><a href="#par">Protein Autoregressive Modeling</a></li>
                        <ul>
                            <li><a href="#decomposer">Multi-Scale Protein Downsampling</a></li>
                            <li><a href="#backbone_autoregressive">Coarse-to-Fine Backbone Autoregressive Modeling</a></li>
                            <ul>
                                <li><a href="#encoder">Autoregressive Transformer</a></li>
                                <li><a href="#decoder">Flow-Based Atomic Decoder</a></li>
                            </ul>
                            <li><a href="#bias">Mitigating Exposure Bias</a></li>
                            <li><a href="#inference">Inference</a></li>
                        </ul>
                        <li><a href="#experiments">Experiments</a></li>
                        <ul>
                            <li><a href="#uncond">Protein Backbone Generation</a></li>
                            <li><a href="#prompt">Zero-Shot Prompted Generation</a></li>
                            <li><a href="#motif">Zero-Shot Motif Scaffolding</a></li>
                            <li><a href="#scaling">Scaling Effects of PAR</a></li>
                            <li><a href="#efficiency">Efficient Sampling</a></li>
                            <li><a href="#multi-scale-ablation">Multi-Scale Formulation</a></li>
                            <li><a href="#expt-exposure-bias">Mitigating Exposure Bias</a></li>
                            <li><a href="#attn">Interpreting Multi-Scale PAR</a></li>
                        </ul>
                        <li><a href="#conclusion">Conclusion</a></li>
                        <li><a href="#citation">BibTeX</a></li>
                    </ul>
                    <hr> <!-- Optional: Add a horizontal rule after the TOC -->
                </div>
                <h2 class="title is-3" id="motivation"> Motivation </h2>
                <div class="content has-text-justified">
                    <p>
                        Deep generative modeling of proteins has emerged as a way to design and model novel structures
                        with desired functions and properties.
                        A widely adopted approach is to directly model the distribution of three-dimensional protein
                        structures, mostly based on diffusion models and their variations (e.g., flow matching).
                        On the other hand, though autoregressive (AR) modeling showing striking scalability, and
                        zero-shot generalization in large language models,
                        AR modeling has received little attention in backbone modeling for 2 main reasons:
                        (i) Extending AR models to continuous data often relies on <b>data discretization</b>, which can
                        reduce structural fidelity and fine-grained details for proteins.
                        (ii) Protein residues exhibit strong <b>bidirectional dependencies</b>, while AR model usually
                        follows a unidirectional order, and thus limits the quality of previous attempts on autoregressive structure generation.
                        A natural question therefore arises: 
                        <blockquote>
                            <em>Can we apply AR modeling to protein backbone design?</em>
                        </blockquote>
                          
                          
                    </p>
                    <figure style="margin-top: 1rem; margin-bottom: 1rem;">
                        <img src="./static/img/generation_over_scale_with_rmsd_4_samples.png"
                            alt="Multi-scale Generation" style="width:100%;">

                        <!-- Add the figcaption below the image -->
                        <figcaption class="has-text-centered is-size-6 mb-3">
                            <strong>Figure 1: Multi-scale Generation with PAR.</strong>
                        </figcaption>
                    </figure>
                </div>
                <h2 class="title is-3" id="contributions"> Major Contributions </h2>
                <div class="content has-text-justified">
                    <p>
                        Our main contributions are summarized as follows:
                    </p>
                    <ul>
                        <li>
                          We present <em>PAR</em>, the <em>first</em> multi-scale AR model for protein backbone generation that addresses key limitations of existing AR methods.
                        </li>
                        <li>
                          PAR comprises multi-scale downsampling, AR transformer, and a flow-based decoder, to directly model C&#945; atom, avoiding discretization loss.
                        </li>
                        <li>
                          We alleviate exposure bias through noisy context learning and scheduled sampling, effectively improving structure generation.
                        </li>
                        <li>
                          Our model shows an interpretable generation process that forms coarse backbone topology and refines it progressively.
                        </li>
                        <li>
                          Benchmarking results show that PAR effectively captures protein data distributions, achieving FPSD score of <strong>161.0</strong> against PDB dataset that further scale with training compute.
                        </li>
                        <li>
                          PAR exhibits efficient sampling and zero-shot generalization potential, reflecting the versatility of AR large language models.
                        </li>
                      </ul>
                      
                </div>

                <div>
                    <h2 class="title is-3" id="par"> Protein Autoregressive Modeling</h2>
                    <p>
                        During training, we downsample a backbone 
                            <span class="katex">\(\mathbf{x} \in \mathbb{R}^{L \times 3}\)</span> into multi-scale representations 
                            <span class="katex">\(\{ \mathbf{x}^{1}, \dots, \mathbf{x}^{n} \}\)</span>.  
                            The <em>AR transformer</em> performs next-scale prediction, producing conditional embeddings 
                            <span class="katex">\((\mathbf{z}^{1}, \dots, \mathbf{z}^{n})\)</span> from 
                            <span class="katex">\(( \text{bos}, \dots, \mathbf{x}^{n-1} )\)</span>.  
                            The shared <em>flow-based decoder</em> learns to denoise backbones 
                            <span class="katex">\(\mathbf{x}^{i}\)</span> at each scale conditioned on 
                            <span class="katex">\(\mathbf{z}^{i}\)</span>. At inference, PAR autoregressively generates 
                            <span class="katex">\(\mathbf{x}^{i}\)</span> until the final structure 
                            <span class="katex">\(\mathbf{x}\)</span> is constructed.
                    </p>
                    <figure style="margin-top: 5rem; margin-bottom: 1rem;">
                        <img src="./static/img/par_with_example.png" style="width:100%;">

                        <!-- Add the figcaption below the image -->
                        <figcaption class="has-text-centered is-size-6 mb-3">
                            <strong>Figure 2: Model Architecture of PAR.</strong>  
                            PAR comprises the autoregressive (AR) transformer 
                            <span class="katex">\(\mathcal{T}_{\theta}\)</span> (left) and the flow-based backbone decoder 
                            <span class="katex">\(\mathcal{v}_{\theta}\)</span> (right).
                          </figcaption>
                    </figure>

                    <h3 class="title is-4" id="decomposer"> Multi-Scale Protein Downsampling</h3>
                    <div class="content has-text-justified">
                        
                        <p>
                            We construct the multi-scale representations of protein structures via hierarchical downsampling to serve as
                            training context and targets for PAR.
                        </p>
                        <div
                            style="border-left: 4px solid #ccc; padding: 1em; background-color: #f9f9f9; font-weight: bold;">
                            $$
                            q_{\text{decompose}} : \mathbf{x} \rightarrow X = \{ \mathbf{x}^{1}, \mathbf{x}^{2}, \ldots, \mathbf{x}^{n} \}
                            = \{ \text{Down}(\mathbf{x}, \texttt{size(1)}), \text{Down}(\mathbf{x}, \texttt{size(2)}), \ldots, \mathbf{x}
                            \}
                            $$

                        </div>
                        <p>
                            The input structure <span class="katex">\(\mathbf{x} \in \mathbb{R}^{L \times 3}\)</span> is decomposed into multi-scale representations 
                            <span class="katex">\(\{ \mathbf{x}^{1}, \dots, \mathbf{x}^{n} \}\)</span> through a scale configuration 
                            <span class="katex">\(\{ \texttt{size(1)}, \texttt{size(2)}, \dots, \texttt{size(n)} \}\)</span>, where 
                            <span class="katex">\(\text{Down}(\mathbf{x}, \texttt{size(i)}) \in \mathbb{R}^{\texttt{size(i)} \times 3}\)</span> denotes a downsampling operation 
                            that interpolates <span class="katex">\(\mathbf{x}\)</span> along the sequence dimension, producing 
                            <span class="katex">\(\texttt{size(i)}\)</span> 3D centroids that provide a coarse structural layout.
                          </p>
                          
                          <p><strong>Scale configuration</strong> can be defined in two ways:</p>
                          <ul>
                            <li>
                              <strong>By length:</strong> scales are chosen as hyperparameters, e.g., 
                              <span class="katex">\(\mathbf{S} = \{64, 128, 256\}\)</span>.  
                              If <span class="katex">\(\mathbf{L} \in (\texttt{size(i)}, \texttt{size(i+1)}]\)</span>, the protein can be generated 
                              with only <span class="katex">\((i+1)\)</span> autoregressive steps.  
                              Empirically, defining scales by length yields slightly better results in modeling data distributions.
                            </li>
                            <li>
                              <strong>By ratio:</strong> scales are adaptively determined based on protein length, e.g., 
                              <span class="katex">\(\mathbf{S} = \{L/4, L/2, L\}\)</span>.  
                              This approach adjusts automatically for different protein lengths.
                            </li>
                          </ul>
                          <p>
                            We adopt length-based scales as the default configuration.  
                            This design enables training PAR with flexible scale configurations.  
                            In the following sections, we describe how this hierarchy of representations is modeled 
                            using the autoregressive transformer and backbone decoder.
                          </p>
                          
                          
                    </div>

                    <h3 class="title is-4" id="backbone_autoregressive"> Coarse-to-Fine Backbone Autoregressive Modeling</h3>
                        <p>
                            We propose to use an AR Transformer with diffusion/flow-based regression loss to enable modeling of CŒ±
                            atoms directly in continuous space. That is, we could write the likelihood as:
                            <div
                            style="border-left: 4px solid #ccc; padding: 1em; background-color: #f9f9f9; font-weight: bold;">
                            
                            <span class="katex">
                                \[
                                p_\theta(X = \{\mathbf{x}^1, \dots, \mathbf{x}^n\}) 
                                = \prod_{i=1}^n p_\theta(\mathbf{x}^{i} \mid X^{&lt; i}) 
                                = \prod_{i=1}^n p_\theta(\mathbf{x}^{i} \mid \mathbf{z}^i = \mathcal{T}_\theta(X^{&lt; i}))
                                \]
                            </span>
                        </div>
                        </p>
                    <h4 class="title is-4" id="encoder"> Autoregressive Transformer for Scale-Wise Conditioning <span class="katex">
                        \(\mathcal{T}_{\theta}\)
                      </span></h4>
                    <div class="content has-text-justified">

                        <p>
                            To formulate the autoregressive order, we leverage the hierarchical nature of proteins,
                            where a protein structure spans multiple levels of representation from coarse tertiary topology 
                            to the finest atomic coordinates. We adopt next-scale prediction to model the per-scale 
                            distribution based on prior coarser scales, ensuring that the <em>bidirectional</em> dependencies 
                            of residues are captured at each scale. We train our autoregressive model (Fig.&nbsp;2, left), 
                            a non-equivariant transformer <span class="math">ùíØ<sub>Œ∏</sub></span>, to produce scale-wise conditioning embeddings 
                            <span class="katex">\(\mathbf{z}^{i}\)</span> for scale <em>i</em> depending on prior scales 
                            <span class="katex">\(\mathbf{X^{\lt i}}=\{\mathbf{x}^{1}, \ldots, \mathbf{x}^{i-1}\}\)</span>:
                          </p>
                          

                        <div
                            style="border-left: 4px solid #ccc; padding: 1em; background-color: #f9f9f9; font-weight: bold;">
                            $$
                            \mathbf{z}^i
                            = \mathcal{T}_{\theta}(X^{\lt i})
                            = \mathcal{T}_{\theta}\left(
                            [\mathrm{bos},\ \mathrm{Up}(\mathbf{x}^{1}, \texttt{size(2)}),\ \ldots,\ \mathrm{Up}(\mathbf{x}^{i-1},
                            \texttt{size(i)})]
                            \right)
                            $$
                        </div>

                        <p>
                            where <span class="katex">\(\mathbf{bos} \in \mathbb{R}^{\texttt{size(1)} \times 3}\)</span> is a learnable embedding,  
                            and <span class="katex">\(\mathrm{Up}(\mathbf{x}^{i-1}, \texttt{size(i)})\)</span> interpolates 
                            <span class="katex">\(\mathbf{x}^{i-1}\)</span> to <span class="katex">\(\texttt{size(i)}\)</span> 3D points.  
                            All inputs are concatenated along the sequence dimension before being fed into 
                            <span class="katex">\(\mathcal{T}_{\theta}\)</span>.  
                            The embedding <span class="katex">\(\mathbf{z}^{i}\)</span> is then used to condition the flow-matching decoder 
                            to predict the backbone coordinates <span class="katex">\(\mathbf{x}^{i}\)</span>.
                          </p>
                          

                        <!-- <div>
          <img src="./static/img/1a26.jpeg" alt="Teaser" style="width:80%;">
        </div> -->

                    </div>

                    <h4 class="title is-4" id="decoder"> Flow-based Atomic Decoder <span class="katex">
                        \(\mathcal{v}_{\theta}\)
                      </span></h4>
                    <div class="content has-text-justified">
                        <p>
                            We enable PAR to directly model CŒ± positions 
                            <span class="katex">\(\mathbf{x}\)</span>, wherein 
                            <span class="katex">\({p}_{\theta}(\mathbf{x} \mid \mathbf{z}^{i})\)</span> is parameterized by an atomic decoder 
                            <span class="katex">\(\mathcal{v}_{\theta}\)</span> with flow matching, which maps a standard normal distribution 
                            to the target data distribution. We condition <span class="katex">\(\mathcal{v}_{\theta}\)</span> with scale-wise 
                            embeddings <span class="katex">\(\mathbf{z}^{i}\)</span> predicted by the AR transformer 
                            <span class="katex">\(\mathcal{T}_{\theta}\)</span> at each scale \(i\) (Fig. 2, right).  
                          
                            During training, we sample noise 
                            <span class="katex">\(\boldsymbol{\varepsilon}^{i} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</span> 
                            and a time variable <span class="katex">\(t^{i} \in [0,1]\)</span>, and compute the interpolated sample as  
                            <span class="katex">\(\mathbf{x}_{t^{i}}^{i} = t^{i} \cdot \mathbf{x}^{i} + (1 - t^{i}) \cdot \boldsymbol{\varepsilon}^{i}\)</span>.  
                          
                            As such, we can jointly train <span class="katex">\(\mathcal{v}_{\theta}\)</span> and 
                            <span class="katex">\(\mathcal{T}_{\theta}\)</span> with a flow-matching (FM) objective.
                          </p>
                          

                        <div
                            style="border-left: 4px solid #ccc; padding: 1em; background-color: #f9f9f9; font-weight: bold;">
                            $$
                            \mathcal{L}(\theta)
                            = \mathbb{E}_{\mathbf{x} \sim p_D} \left[
                            \frac{1}{n} \sum_{i=1}^{\texttt{n}}
                            \frac{1}{\texttt{size}(i)}
                            \mathbb{E}_{t^i \sim p(t^i),\, \mathbf{\epsilon}^i \sim \mathcal{N}(0, I)}
                            \left\|
                            v_{\theta}\left(\mathbf{x}_{t^i}^i,\, t^i,\, \mathbf{z}^i \right)
                            - \left(\mathbf{x}^i - \mathbf{\epsilon}^i\right)
                            \right\|^2
                            \right]
                            $$
                        </div>

                        <p>
                            where <span class="katex">\({p}_{D}(\mathbf{x})\)</span> denotes the training data distribution and 
                            <span class="katex">p(t)</span> denotes the \(t\)-sampling distribution in training.  
                            The conditioning embedding <span class="katex">\(\mathbf{z}^{i}\)</span> is injected into the atomic decoder network 
                            <span class="katex">\(\mathcal{v}_{\theta}\)</span> through adaptive layer norms.  
                            <!-- We further concatenate a learnable scale embedding before feeding into the decoder. -->
                          </p>
                          


                    </div>

                    <h3 class="title is-4" id="bias"> Mitigating Exposure Bias</h3>
                    <div class="content has-text-justified">
                        <p>
                            Training AR models typically uses <i>teacher forcing</i>, where ground-truth data are fed as
                            context to stabilize learning.
                            However, during inference the model is conditioned on its own predictions, creating a
                            training-inference mismatch
                            known as <i>exposure bias</i>. Errors can then accumulate across autoregressive steps,
                            degrading output quality.
                            Our preliminary study shows that teacher forcing greatly reduces the designability of
                            generated structures.
                            To mitigate this, we adapt <i>Noisy Context Learning (NCL)</i> and <i>Scheduled
                                Sampling (SS)</i>, techniques from language and
                            image AR modeling, for PAR.
                        </p>
                    </div>

                    <h3 class="title is-4" id="inference"> Inference</h3>
                    <div class="content has-text-justified">
                        <p>
                            At inference, the autoregressive transformer first produces 
                            <span class="katex">\(\mathbf{z}^{1}\)</span> at the coarsest scale, which conditions the flow-matching decoder 
                            <span class="katex">\(\mathcal{v}_{\theta}\)</span> to generate 
                            <span class="katex">\(\mathbf{x}^{1}\)</span> either via ODE or SDE sampling.  
                            We upsample <span class="katex">\(\mathbf{x}^{1}\)</span> using 
                            <span class="katex">\(\texttt{Up}(\mathbf{x}^{1}, \texttt{size(2)})\)</span> and send it back into the 
                            autoregressive transformer to predict the next-scale embedding 
                            <span class="katex">\(\mathbf{z}^{2}\)</span>.  
                            This coarse-to-fine process iterates \(n\) times until the flow-matching model generates the full-resolution backbone 
                            <span class="katex">\(\mathbf{x}\)</span>.  
                            KV cache is applied throughout the autoregressive process for efficiency.
                          </p>
                          
                          <p>
                            Leveraging the learned flow network 
                            <span class="katex">\(\mathcal{v}_{\theta}\)</span>, sampling can be performed at each scale through the ordinary differential equation (ODE):  
                            <span class="katex">\(\mathrm{d} \mathbf{x}_{t} = \mathcal{v}_{\theta}(\mathbf{x}_{t}, t)\, \mathrm{d}t\)</span>,  
                            with the scale superscript \(i\) omitted for simplicity.  
                            Moreover, we can define the stochastic differential equation (SDE) for sampling:
                          </p>
                          

                        <div
                            style="border-left: 4px solid #ccc; padding: 1em; background-color: #f9f9f9; font-weight: bold;">
                            $$
                            d \mathbf{x}_t
                            = v_{\theta}(\mathbf{x}_t, t)\, dt
                            + g(t)\, s_{\theta}(\mathbf{x}_t, t)\, dt
                            + \sqrt{2 g(t)\, \gamma}\, d \mathcal{W}_t
                            $$
                        </div>

                        <p>
                            where <span class="katex">\(g(t)\)</span> is a time-dependent scaling function for the score function
                            <span class="katex">\(s_{\theta}(\mathbf{x}_t, t)\)</span>, and the noise term <span class="katex">\(\gamma\)</span> is a noise scaling parameter,
                            and <span class="katex">\(\mathcal{W}_t\)</span> is a standard Wiener process.
                            The score function, defined as the gradient of the log-probability of the noisy data
                            distribution at time <span class="katex">\(t\)</span>, could be computed as:
                        </p>

                        <div
                            style="border-left: 4px solid #ccc; padding: 1em; background-color: #f9f9f9; font-weight: bold;">
                            $$
                            s_{\theta}(\mathbf{x}_t, t)
                            = \frac{t\, v_{\theta}(\mathbf{x}_t, t) - \mathbf{x}_t}{1 - t}
                            $$
                        </div>

                    </div>
                </div>

                <div>
                    <h2 class="title is-3 mt-6" id="par"> Experiments</h2>

                    <h3 class="title is-4" id="uncond"> Protein Backbone Generation</h3>
                    
                    <div class="content has-text-justified">

                        <p>
                            We compare PAR with other baselines on unconditional backbone generation benchmark as shown in Table 1.
                            To better reflect the goal of unconditional protein generation as modeling the full data distribution, we adopt <strong>FPSD</strong>, which jointly measures quality and diversity by comparing generated and reference distributions, analogous to FID in image generation.
                            As shown in <strong>Table 1</strong>, <strong>PAR</strong> generates samples that closely match the reference data distribution and maintains competitive designability.
                            On FPSD, <strong>PAR</strong> achieves scores of <span class="katex">211.8</span> against <strong>AFDB</strong> and <span class="katex">231.5</span> against <strong>PDB</strong>.
                            By reducing the noise scaling parameter <span class="katex">\(\gamma\)</span> from <span class="katex">0.45</span> to <span class="katex">0.3</span> in SDE sampling, we reduce sampling stochasticity and further improve sample quality, improving the designability from <span class="katex">\(88.0\%\)</span> to <span class="katex">\(96.0\%\)</span>.
                            After fine-tuning, <strong>PAR</strong> achieved <span class="katex">\(96.6\%\)</span> designability and <strong>161.0</strong> FPSD against the <strong>PDB</strong>, highlighting its superior distributional fidelity compared to pure diffusion-based baselines.
                        </p>
                        
                    </div>

                    <div class="container is-max-desktop content">
                        <figure class="table-container mt-5 mb-5">
                          <figcaption class="has-text-centered is-size-6 mb-3">
                            <b>Table 1:</b>
                            <strong>Unconditional backbone generation performance.</strong>
                            We follow FPSD and fS to evaluate the model's ability to capture the data distribution.
                            <span>PAR<sub>pdb</sub> denotes the 400M model finetuned on the PDB subset.</span>
                          </figcaption>
                      
                          <img src="./static/img/PAR_uncond_gen_table.png" alt="Unconditional backbone generation performance table" style="width:100%;">
                        </figure>                      
                    </div>

                    <h3 class="title is-4" id="prompt"> Zero-Shot Prompted Generation</h3>
                    
                    <div class="content has-text-justified">
                        <p>
                            Proteins possess hierarchical and complex structures, which makes it challenging to directly specify 
                            a target shape and design proteins accordingly. By leveraging PAR‚Äôs coarse-to-fine generation, 
                            a simple prompt (e.g., 16 points) can specify a protein‚Äôs coarse layout, from which the model generates 
                            the complete structure as shown in Fig. 3.
                            In particular, we first obtain a 16-point input prompt either by downsampling a real protein structure 
                            from the test set or by specifying the points manually (the top row in Fig. 3). Using a 5-scale PAR 
                            (<i>S = {16, 32, 64, 128, 256}</i>), we initialize the first-scale prediction with the 16-point prompt 
                            and autoregressively upsample until the full protein structure is generated, as illustrated in the bottom row of Fig. 3. 
                            <br>
                            <br>
                            üìå Following this process, PAR can generate a new structure that <strong>preserves the coarse structural layout</strong> 
                            (first five examples), and <strong>explore entirely novel structures</strong> (last three examples). 
                        </p>
                    </div>

                    <figure style="margin-top: 1rem; margin-bottom: 1rem;">
                        <img src="./static/img/prompt_shape-crop.png" style="width:100%;">

                        <!-- Add the figcaption below the image -->
                        <figcaption class="has-text-centered is-size-6 mb-3">
                            <p>
                                <strong>Figure 3: Backbone generation with human prompt.</strong>
                                Given a small number of points (e.g., 16) as prompt, PAR can generate protein backbones that adhere
                                to the global arrangements specified by these points, <em>without</em> any finetuning.
                                For visualization, input points are interpolated to match the length of the generated structure.
                            </p>
                                
                        </figcaption>
                    </figure>

                    <h3 class="title is-4" id="motif"> Zero-Shot Motif Scaffolding</h3>
                    <div class="content has-text-justified">
                        <p>
                            Besides the point-based layout, PAR can preserve finer-grained prompts like atomic coordinates. 
                            Fig. 4 highlights the zero-shot motif scaffolding capabilities of PAR. 
                            Using a 5-scale PAR, we downsample a raw protein structure into five scales and teacher-force the 
                            ground-truth motif coordinates at each scale before propagating into the next scale. 
                            To avoid clashes or discontinuities, we superimpose the ground-truth motif residues and the generated motif segments before replacement. 
                            <br>
                            <br>
                            üìå With no fine-tuning and no conditioning, PAR generates <strong>plausible scaffolds</strong> that preserve motif structures with high fidelity. 
                            This stands in contrast to diffusion or flow-based frameworks, which typically require fine-tuning on additional conditions such as masks or motif coordinates, or rely on decomposition strategies.
                            </p>
                            
                            <p>
                            Moreover, the generated scaffolds differ substantially from the input structure, showing that PAR generates structurally diverse scaffolds rather than merely copying. 
                            For example, the leftmost example in Fig. 4 preserves the yellow motif helix while introducing new secondary structure elements such as Œ≤-sheet and loops, in contrast to the original helices.
                            We provide benchmarking results in the appendix.
                            </p>
                            
                    </div>

                    <figure style="margin-top: 1rem; margin-bottom: 1rem;">
                        <img src="./static/img/motif_scaffold.png" style="width:100%;">

                        <!-- Add the figcaption below the image -->
                        <figcaption class="has-text-centered is-size-6 mb-3">
                            <p>
                                <strong>Figure 4: Zero-shot motif scaffolding.</strong>
                                Given a motif structure, PAR can generate diverse, plausible scaffold structures that accurately preserve 
                                the motif via teacher-forcing the motif coordinates at each scale, without additional conditioning or fine-tuning.
                            </p>
                                
                        </figcaption>
                    </figure>

                    <h3 class="title is-4" id="scaling"> Scaling Effects of PAR</h3>
                    <div class="content has-text-justified">
                        <p>
                            PAR demonstrates favorable behavior when scaling both model size and training duration,
                            effectively <strong>improving its ability to capture the protein data distribution</strong> with FPSD scores of 
                            187 against PDB and 170 against AFDB (first two columns in Fig. 5). 
                            Further, the fS scores, which reflect <strong>quality and diversity</strong>, increase with larger model sizes 
                            and greater computational budgets.
                            <br>
                            </p>
                            
                            <p>
                                Meanwhile, we empirically observe that scaling the autoregressive transformer has minimal impacts 
                                on the evaluation results.
                                This allows us to reduce computational costs and prioritize increasing the backbone decoder's model 
                                capacity that effectively improves generation quality. 
                                We provide more discussion on varying model sizes in the appendix.
                            </p>
                            
                    </div>

                    <figure style="margin-top: 1rem; margin-bottom: 1rem;">
                        <img src="./static/img/scaling.png" style="width:100%;">

                        <!-- Add the figcaption below the image -->
                        <figcaption class="has-text-centered is-size-6 mb-3">
                            <p>
                                <strong>Figure 5: Scaling effects of PAR.</strong>
                                Performance of four metrics over varying training steps and model sizes:
                                (a) FPSD vs. PDB, 
                                (b) FPSD vs. AFDB, 
                                (c) fS(T), 
                                (d) sc-RMSD.
                                </p>
                                
                        </figcaption>
                    </figure>

                    <h3 class="title is-4" id="efficiency"> Efficient Sampling</h3>
                    <div class="content has-text-justified">
                        <p>
                            While <strong>Tab. 3</strong> reports results using a uniform number of sampling steps across scales, 
                            the multi-scale formulation of PAR actually offers advantages in sampling efficiency. 
                            More specifically, (1) sampling at the coarser scale (e.g., first scale) is more efficient than 
                            sampling at finer scales (e.g., 2nd scale) due to shorter sequence length; 
                            (2) we can use fewer sampling steps at finer scales than coarser scales. 
                            
                            <br>
                            <br>
                            üìå <strong> Efficient sampling at finer scales:</strong> As shown in Tab. 4, by using SDE sampling only at the first scale,
                            and switching to ODE sampling for the remaining scales, PAR could dramatically reduce 
                            the diffusion steps from 400 to 2 steps at the last two scales without harming designability (97%), 
                            yielding a 2√ó inference speedup. 
                            This is possible because a high-quality coarse topology places 
                            the model near high-density regions, enabling efficient refinement with ODE sampling.
                        </p>
                        
                        
                        <p>
                            üìå <strong> 2.5√ó inference speedup versus single-scale baselines.</strong> Compared to the single-scale 400-step baseline, PAR achieves 1.96√ó and 2.5√ó sampling speedup 
                            at length 150 and 200, respectively. 
                            This improvement is driven by speeding up the final scales, where the longer sequence lengths 
                            cause computational costs to grow quadratically in transformer architectures. 
                            Moreover, the computational costs remain constant at the first scale because it has a fixed size 64, 
                            even when generating longer sequences.
                            For single-scale models, naively reducing the SDE sampling
                            steps significantly harms designability.
                        </p>

                        <p>
                            üìå <strong> Orchestrating SDE and ODE sampling.</strong> 
                            Crucially, SDE sampling at the first scale is necessary for establishing a reliable global topology, 
                            given that ODE-only sampling exhibits poor designability. 
                        </p>
                        
                    </div>

                    <div class="container is-max-desktop content">
                        <figure class="table-container mt-5 mb-5">
                          <figcaption class="has-text-centered is-size-6 mb-3">
                            <b>Table 2:</b>
                            <strong>Performance of different sampling methods and steps.</strong>
                            Combining SDE and ODE sampling across scales yields a 
                            \(2.5\times\) inference speedup compared to the single-scale 
                            400-step baseline, shown in the first and the last row.  
                            We generate 100 samples at each length.
                          </figcaption>
                      
                          <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                            <thead>
                              <tr>
                                <th rowspan="2" class="is-vcentered has-text-centered">Sampling</th>
                                <th rowspan="2" class="is-vcentered has-text-centered">Steps</th>
                                <th colspan="2" class="has-text-centered">Length 150</th>
                                <th colspan="2" class="has-text-centered">Length 200</th>
                              </tr>
                              <tr>
                                <th class="has-text-centered">Time (s)</th>
                                <th class="has-text-centered">Design. (%)</th>
                                <th class="has-text-centered">Time (s)</th>
                                <th class="has-text-centered">Design. (%)</th>
                              </tr>
                            </thead>
                      
                            <tbody>
                              <!-- Proteina SDE -->
                              <tr>
                                <td rowspan="2">Proteina (SDE)</td>
                                <td>0/0/400</td>
                                <td class="has-text-centered">131</td>
                                <td class="has-text-centered">97%</td>
                                <td class="has-text-centered">170</td>
                                <td class="has-text-centered">92%</td>
                              </tr>
                              <tr>
                                <td>0/0/200</td>
                                <td class="has-text-centered">67</td>
                                <td class="has-text-centered">89%</td>
                                <td class="has-text-centered">86</td>
                                <td class="has-text-centered">80%</td>
                              </tr>
                      
                              <!-- All SDE -->
                              <tr>
                                <td rowspan="2">All SDE</td>
                                <td>400/400/400</td>
                                <td class="has-text-centered">312</td>
                                <td class="has-text-centered">97%</td>
                                <td class="has-text-centered">351</td>
                                <td class="has-text-centered">94%</td>
                              </tr>
                              <tr>
                                <td>400/400/2</td>
                                <td class="has-text-centered">184</td>
                                <td class="has-text-centered">0%</td>
                                <td class="has-text-centered">‚Äì</td>
                                <td class="has-text-centered">‚Äì</td>
                              </tr>
                      
                              <!-- All ODE -->
                              <tr>
                                <td>All ODE</td>
                                <td>400/400/400</td>
                                <td class="has-text-centered">312</td>
                                <td class="has-text-centered">28%</td>
                                <td class="has-text-centered">‚Äì</td>
                                <td class="has-text-centered">‚Äì</td>
                              </tr>
                      
                              <!-- S/S/O -->
                              <tr>
                                <td rowspan="2">S/S/O</td>
                                <td>400/400/400</td>
                                <td class="has-text-centered">312</td>
                                <td class="has-text-centered">98%</td>
                                <td class="has-text-centered">‚Äì</td>
                                <td class="has-text-centered">‚Äì</td>
                              </tr>
                              <tr>
                                <td>400/400/2</td>
                                <td class="has-text-centered">184</td>
                                <td class="has-text-centered">99%</td>
                                <td class="has-text-centered">186</td>
                                <td class="has-text-centered">91%</td>
                              </tr>
                      
                              <!-- S/O/O -->
                              <tr>
                                <td rowspan="2">S/O/O</td>
                                <td>400/400/400</td>
                                <td class="has-text-centered">312</td>
                                <td class="has-text-centered">96%</td>
                                <td class="has-text-centered">‚Äì</td>
                                <td class="has-text-centered">‚Äì</td>
                              </tr>
                              <tr>
                                <td>400/2/2</td>
                                <td class="has-text-centered"><b>67</b></td>
                                <td class="has-text-centered">97%</td>
                                <td class="has-text-centered"><b>68</b></td>
                                <td class="has-text-centered">94%</td>
                              </tr>
                      
                            </tbody>
                          </table>
                        </figure>
                      </div>
                      
                      <h3 class="title is-4" id="multi-scale-ablation"> Multi-Scale Formulation</h3>
                      <p>
                        We ablate the effect of defining scale <em>by length</em> versus <em>ratio</em>.
                        Table 3 shows that under comparable levels of upsampling ratio 
                        (<span class="katex">\(\{64, 128, 256\}\)</span> and <span class="katex">\(\{L/4, L/2, L\}\)</span>), 
                        the <em>by-length</em> strategy outperforms <em>by-ratio</em>.
                        </p>
                        <p>
                            Meanwhile, PAR obtains better designability and FPSD when increasing from two scales to three scales. 
                            Beyond this point, increasing the scale configurations to four and five scales results in degraded designability, 
                            potentially due to error accumulation and exposure bias. These results support our choice of adopting the 3-scale PAR as the default. 
                            All results are obtained using the 60M model.
                        </p>
                    
                      <div class="container is-max-desktop content">
                        <figure class="table-container mt-5 mb-5">
                            <figcaption class="has-text-centered is-size-6 mb-3">
                                <b>Table 3:</b>
                                <strong>Multi-scale formulation.</strong>
                                We ablate different strategies for scale configuration in downsampling using a smaller PAR (60M).
                            </figcaption>

                            <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                                <thead>
                                    <tr>
                                        <th rowspan="2" class="is-vcentered">Define scale</th>
                                        <th colspan="1" class="has-text-centered">Designability<br>(% ‚Üë)</th>
                                        <th colspan="1" class="has-text-centered">sc-RMSD ‚Üì</th>
                                        <th colspan="2" class="has-text-centered">FPSD vs.</th>
                                        <th rowspan="2" class="has-text-centered">fS<br>(C / A / T ‚Üë)</th>
                                    </tr>
                                    <tr>
                                        <th class="has-text-centered">‚Äì</th>
                                        <th class="has-text-centered">‚Äì</th>
                                        <th class="has-text-centered">PDB ‚Üì</th>
                                        <th class="has-text-centered">AFDB ‚Üì</th>
                                    </tr>
                                </thead>

                                <tbody>
                                    <tr>
                                        <td>{64, 256}</td>
                                        <td class="has-text-centered">83.0</td>
                                        <td class="has-text-centered">1.38</td>
                                        <td class="has-text-centered">282.85</td>
                                        <td class="has-text-centered">274.32</td>
                                        <td class="has-text-centered">2.14 / 6.58 / 20.66</td>
                                    </tr>

                                    <tr>
                                        <td>{64, 128, 256}</td>
                                        <td class="has-text-centered">85.0</td>
                                        <td class="has-text-centered">1.39</td>
                                        <td class="has-text-centered">279.63</td>
                                        <td class="has-text-centered">267.35</td>
                                        <td class="has-text-centered">2.15 / 6.52 / 20.35</td>
                                    </tr>

                                    <tr>
                                        <td>{64, 128, 192, 256}</td>
                                        <td class="has-text-centered">77.8</td>
                                        <td class="has-text-centered">1.55</td>
                                        <td class="has-text-centered">296.70</td>
                                        <td class="has-text-centered">282.69</td>
                                        <td class="has-text-centered">2.05 / 6.04 / 18.69</td>
                                    </tr>

                                    <tr>
                                        <td>{64, 96, 128, 192, 256}</td>
                                        <td class="has-text-centered">81.0</td>
                                        <td class="has-text-centered">1.51</td>
                                        <td class="has-text-centered">276.00</td>
                                        <td class="has-text-centered">263.58</td>
                                        <td class="has-text-centered">2.17 / 6.31 / 20.65</td>
                                    </tr>

                                    <tr>
                                        <td>{L/4, L/2, L}</td>
                                        <td class="has-text-centered">86.4</td>
                                        <td class="has-text-centered">1.49</td>
                                        <td class="has-text-centered">310.64</td>
                                        <td class="has-text-centered">298.30</td>
                                        <td class="has-text-centered">2.00 / 5.87 / 18.91</td>
                                    </tr>
                                </tbody>
                            </table>
                        </figure>
                    </div>
                    
                    <h3 class="title is-4" id="expt-exposure-bias"> Mitigating Exposure Bias</h3>
                    <p>
                    Table 4 shows that noisy context learning
                    effectively improves the sc-RMSD of the generated structure from 2.20 to 1.58, and reduces FPSD against
                    AFDB to 23.69 when using ODE sampling. The designability further improved to 1.48 along with scheduled sampling, 
                    which makes the training process more aligned with the inference scenario. Results are obtained
                    with 60M PAR trained for 100K steps.
                    </p>
                    <div class="container is-max-desktop content">
                        <figure class="table-container mt-5 mb-5">
                            <figcaption class="has-text-centered is-size-6 mb-3">
                                <b>Table 4:</b>
                                <strong>Mitigating exposure bias for PAR.</strong>
                            </figcaption>

                            <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                                <thead>
                                    <tr>
                                        <th class="has-text-centered">Method</th>
                                        <th class="has-text-centered">sc-RMSD ‚Üì</th>
                                        <th class="has-text-centered">FPSD vs.<br>(PDB / AFDB) ‚Üì</th>
                                        <th class="has-text-centered">fS<br>(C / A / T ‚Üë)</th>
                                    </tr>
                                </thead>

                                <tbody>
                                    <tr>
                                        <td>Teacher Forcing</td>
                                        <td class="has-text-centered">2.20</td>
                                        <td class="has-text-centered">99.66 / 37.64</td>
                                        <td class="has-text-centered">2.53 / 5.56 / 29.67</td>
                                    </tr>

                                    <tr>
                                        <td>+ NCL</td>
                                        <td class="has-text-centered">1.58</td>
                                        <td class="has-text-centered">89.70 / 23.69</td>
                                        <td class="has-text-centered">2.54 / 5.85 / 28.37</td>
                                    </tr>

                                    <tr>
                                        <td>+ NCL & SS</td>
                                        <td class="has-text-centered">1.48</td>
                                        <td class="has-text-centered">90.66 / 24.59</td>
                                        <td class="has-text-centered">2.54 / 5.84 / 28.77</td>
                                    </tr>
                                </tbody>
                            </table>
                        </figure>
                    </div>
                    <h3 class="title is-4" id="attn"> Interpreting Multi-Scale PAR</h3>
                    <div class="content has-text-justified">

                        <p>
                            We visualize the attention maps of the autoregressive transformer at each scale (Fig. 6). 
                            We average the attention scores within each scale, normalize them such that the scores across scales sum to 1, 
                            and average them over 50 test samples to obtain the scale-level attention distribution during inference.
                            We summarize three key observations:
                            </p>
                            
                            <p>
                            <i>(i)</i> Most scales barely attend to the first scale, since the input to this scale, a <code>bos</code> token, carries little structural signal.  
                            </p>
                            
                            <p>
                            <i>(ii)</i> Each scale primarily attends to the previous scale, which typically contains richer contextual and structural information.
                            </p>
                            
                            <p>
                            <i>(iii)</i> Despite focusing most heavily on the current scale, the model still retains non-negligible attention to earlier scales.
                            <br>
                            <br>
                            üìå This indicates that PAR effectively integrates information across multiple scales and <strong>maintains structural consistency</strong> during generation.
                            <br>
                            </p>
                            
                    </div>
                    

                    <figure style="margin-top: 1rem; margin-bottom: 1rem;">
                        <img src="./static/img/attn_map.png" style="width:80%;">

                        <!-- Add the figcaption below the image -->
                        <figcaption class="has-text-centered is-size-6 mb-3">
                            <p>
                                <strong>Figure 6:</strong> Visualization of the average attention scores in PAR autoregressive transformer over 5 scales,
                                obtained from samples with lengths in (128, 256). 
                                We provide attention map visualization for shorter proteins in ¬ßC.3.
                            </p>                            
                                
                        </figcaption>
                    </figure>

                </div>

                <h2 class="title is-3" id="conclusion"> Conclusion </h2>
                <div class="content has-text-justified">
                    <p>
                        PAR is the first multi-scale autoregressive model for protein backbone generation, offering a general framework that includes flow-based methods as a special case. PAR addressed limitations of standard autoregressive models, such as unidirectional dependency, discretization, and exposure bias. Our method robustly models structures over multiple granularities and in turn enables strong zero-shot generalization. This capability includes coarse-prompted conditional generation using points (e.g., 16 points) as structural layout and finer-grained controls such as atomic-coordinate-based motif scaffolding. For unconditional backbone generation, PAR exhibits powerful distributional fidelity and generation quality. The analysis of scale-level attention map provides additional insights into how the multi-scale formulation operates.
                        </p>
                        
                        <p>
                        We hope that PAR unlocks the potential of autoregressive modeling for protein design. Some promising open directions include:
                        </p>
                        
                        <p>
                        (1) <strong>Conformational dynamics modeling.</strong> PAR can, in principle, perform zero-shot modeling of conformational distributions: we downsample a structure and upsample it with PAR to mimic local molecular dynamics. We leave this exciting application for future research.
                        </p>
                        
                        <p>
                        (2) <strong>All-atom modeling.</strong> This work focuses on backbone CŒ± atoms to prioritize autoregressive design, but it is natural to extend to full-atom representations. The multi-scale framework offers an advantage for flexible zero-shot prompt-based all-atom designs.
                        </p>
                        
                </div>
            </div>
        </div>


    </section>

    <style>
        .video-grid-two-cols {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            /* Two columns */
            gap: 10px;
            /* Gap between videos */
            width: 60%;
            /* Set the container width to 60% */
            margin: 0 auto;
            /* Center the container horizontally */
        }

        .video-grid-two-cols video {
            width: 100%;
            /* Videos fill the container width */
            height: auto;
        }
    </style>




    <!-- <section class="section" id="Acknowledgements">
      <div class="container is-max-desktop content">
        <h2 class="title is-3">Acknowledgements</h2>
        The data collection efforts behind <a href="https://taodataset.org/">TAO</a> dataset are crucial for the
        realization of TAO-Amodal.
        We also thank <a href="https://github.com/Ali2500/BURST-benchmark">BURST</a> dataset for its collection of modal
        mask annotations.
        Amodal annotations for this dataset were provided by AnnotateX. We thank Neehar Peri and Jason Zhang from CMU
        for their detailed feedback on the dataset and experiments.
      </div>
    </section> -->


    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title is-3" id="citation">BibTeX</h2>
            <pre><code>
      @article{par,
          title={Protein Autoregressive Modeling via Multiscale Structure Generation},
      }
          </code></pre>
        </div>
    </section>



    <footer class="footer">
        <div align="center" class="container">
            <div class="columns is-centered">
                <div class="content">
                    This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
                    You are free to borrow the source code of this website, we just ask that you link back to this page
                    in the footer.
                    <br> This website is licensed under a <a rel="license"
                        href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                </div>
            </div>
        </div>
    </footer>


</body>

</html>